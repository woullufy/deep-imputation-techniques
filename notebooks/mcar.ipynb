{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T21:29:46.517132Z",
     "start_time": "2025-12-03T21:29:46.515676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import KNNImageImputer, MeanImageImputer\n",
    "from utils import Missingness\n",
    "from utils import get_device\n",
    "from utils import get_raw_data\n",
    "from utils import plot_dec_performance\n",
    "from utils import run_dec_pipeline"
   ],
   "id": "681c04f3566a6aa9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T21:29:46.684278Z",
     "start_time": "2025-12-03T21:29:46.682727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missingness = Missingness()\n",
    "knn_imputer = KNNImageImputer(k=5)\n",
    "mean_imputer = MeanImageImputer()\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "missingness_percentages = np.arange(0, 100, 10)"
   ],
   "id": "f442894fd416580b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading data",
   "id": "816c79de8d3ca7f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T21:29:44.013629Z",
     "start_time": "2025-12-03T21:29:43.822617Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_x, labels, indices = get_raw_data('mnist', device=device)",
   "id": "4fba8e610036e24b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Knn Imputation",
   "id": "a11cda64a397d386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T21:02:43.591459Z",
     "start_time": "2025-12-03T21:02:43.590099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ari_scores_knn = []\n",
    "nmi_scores_knn = []"
   ],
   "id": "c85358247d0d88e5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T21:02:56.922750Z",
     "start_time": "2025-12-03T21:02:44.276117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for mcar_percent in missingness_percentages:\n",
    "    missing_rate_float = mcar_percent / 100.0\n",
    "\n",
    "    ari, nmi = run_dec_pipeline(\n",
    "        X_clean=tensor_x,\n",
    "        y_true=labels,\n",
    "        data_indices=indices,\n",
    "        missingness=missingness,\n",
    "        corruption_type='mcar',\n",
    "        missing_rate=missing_rate_float,\n",
    "        imputer=knn_imputer,\n",
    "        device=device,\n",
    "        ae_epochs=20,\n",
    "        dec_epochs=50\n",
    "    )\n",
    "\n",
    "    ari_scores_knn.append(ari)\n",
    "    nmi_scores_knn.append(nmi)"
   ],
   "id": "4d7ae9944698e7a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNo corruption applied\n",
      "\tRunning imputation: KNNImageImputer\n",
      "\t- Training Autoencoder\n",
      "Epoch 5/20: average loss = 0.0185\n",
      "Epoch 10/20: average loss = 0.0130\n",
      "Epoch 15/20: average loss = 0.0114\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m mcar_percent \u001B[38;5;129;01min\u001B[39;00m missingness_percentages:\n\u001B[32m      2\u001B[39m     missing_rate_float = mcar_percent / \u001B[32m100.0\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     ari, nmi = \u001B[43mrun_dec_pipeline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX_clean\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdata_indices\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissingness\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissingness\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcorruption_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmcar\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissing_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissing_rate_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m        \u001B[49m\u001B[43mimputer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mknn_imputer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m        \u001B[49m\u001B[43mae_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdec_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m50\u001B[39;49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m     ari_scores_knn.append(ari)\n\u001B[32m     18\u001B[39m     nmi_scores_knn.append(nmi)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/deep-imputation-techniques/utils/pipeline.py:66\u001B[39m, in \u001B[36mrun_dec_pipeline\u001B[39m\u001B[34m(X_clean, y_true, data_indices, missingness, missing_rate, corruption_type, imputer, device, ae_epochs, dec_epochs, n_clusters, latent_dim, n_features)\u001B[39m\n\u001B[32m     63\u001B[39m ae_optimizer = optim.Adam(ae.parameters(), lr=\u001B[32m0.001\u001B[39m)\n\u001B[32m     64\u001B[39m ae_loss_fn = MSELoss()\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m \u001B[43mtrain_autoencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mae\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mae_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mae_optimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m    \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mae_loss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mae_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmissingness\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[38;5;66;03m# ----- DEC training -----\u001B[39;00m\n\u001B[32m     77\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[33m- Training DEC\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/deep-imputation-techniques/utils/training_ae.py:40\u001B[39m, in \u001B[36mtrain_autoencoder\u001B[39m\u001B[34m(model, train_loader, optimizer, loss_fn, epochs, missingness, corruption_type, image_indices, device, **corruption_kwargs)\u001B[39m\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     38\u001B[39m     noisy_x = x\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m x_hat, z = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoisy_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     41\u001B[39m loss = loss_fn(x_hat, x.view(x.size(\u001B[32m0\u001B[39m), -\u001B[32m1\u001B[39m))\n\u001B[32m     43\u001B[39m optimizer.zero_grad()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/deep-imputation-techniques/models/autoencoder.py:35\u001B[39m, in \u001B[36mAutoencoder.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     31\u001B[39m     x = x.view(x.size(\u001B[32m0\u001B[39m), -\u001B[32m1\u001B[39m)\n\u001B[32m     33\u001B[39m x = torch.nan_to_num(x, nan=\u001B[32m0.0\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m z = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     36\u001B[39m x_hat = \u001B[38;5;28mself\u001B[39m.decoder(z)\n\u001B[32m     38\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m x_hat, z\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    246\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    247\u001B[39m \u001B[33;03mRuns the forward pass.\u001B[39;00m\n\u001B[32m    248\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m     \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    251\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/bachelor/.venv12/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m    131\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    132\u001B[39m \u001B[33;03m    Runs the forward pass.\u001B[39;00m\n\u001B[32m    133\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Missingness': missingness_percentages,\n",
    "    'ARI': ari_scores_knn,\n",
    "    'NMI': nmi_scores_knn\n",
    "})\n",
    "\n",
    "print(results_df)"
   ],
   "id": "984c5cc885a5a9c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_dec_performance(\n",
    "    missingness_percentages=missingness_percentages,\n",
    "    score_arrays=[ari_scores_knn, nmi_scores_knn],\n",
    "    labels=['ARI', 'NMI'],\n",
    "    title='DEC Clustering Performance (KNN Imputation)'\n",
    ")"
   ],
   "id": "f224ab5b1631e696",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mean imputation",
   "id": "69f2ac7c56fc2529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ari_scores_mean = []\n",
    "nmi_scores_mean = []"
   ],
   "id": "86f779dcda8e7e59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for mcar_percent in missingness_percentages:\n",
    "    missing_rate_float = mcar_percent / 100.0\n",
    "\n",
    "    ari, nmi = run_dec_pipeline(\n",
    "        X_clean=tensor_x,\n",
    "        y_true=labels,\n",
    "        data_indices=indices,\n",
    "        missingness=missingness,\n",
    "        corruption_type='mcar',\n",
    "        missing_rate=missing_rate_float,\n",
    "        imputer=mean_imputer,\n",
    "        device=device,\n",
    "        ae_epochs=20,\n",
    "        dec_epochs=50\n",
    "    )\n",
    "\n",
    "    ari_scores_mean.append(ari)\n",
    "    nmi_scores_mean.append(nmi)"
   ],
   "id": "a9d590fd9983540a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Missingness': missingness_percentages,\n",
    "    'ARI (Mean-DEC)': ari_scores_mean,\n",
    "    'NMI (Mean-DEC)': nmi_scores_mean\n",
    "})\n",
    "\n",
    "print(results_df)"
   ],
   "id": "f79bb76a9d5dc775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_dec_performance(\n",
    "    missingness_percentages=missingness_percentages,\n",
    "    score_arrays=[ari_scores_mean, nmi_scores_mean],\n",
    "    labels=['ARI', 'NMI'],\n",
    "    title='DEC Clustering Performance (Mean Imputation)'\n",
    ")"
   ],
   "id": "349797578e5ae7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Denoising Autoencoder",
   "id": "fc1ac54cfefb780b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ari_scores_knn = []\n",
    "# nmi_scores_knn = []\n",
    "#\n",
    "# corruption_type = \"mcar\"\n",
    "# missingness_percentages = np.arange(0, 30, 10)"
   ],
   "id": "409a6465c105f78c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for mcar_percent in missingness_percentages:\n",
    "#     missing_rate_float = mcar_percent / 100.0\n",
    "#     print(f\"\\n-------- Missingness percentage {missing_rate_float} --------\")\n",
    "#\n",
    "#     corruption_kwargs = {\"missing_rate\": missing_rate_float}\n",
    "#\n",
    "#     # X_missing_flat, _ = missingness.apply_corruption(\n",
    "#     #     tensor_x,\n",
    "#     #     corruption_type='mcar',\n",
    "#     #     missing_rate=missing_rate_float\n",
    "#     # )\n",
    "#     #\n",
    "#     # X_missing_image = X_missing_flat.view(-1, 1, H_W, H_W)\n",
    "#     #\n",
    "#     # X_imputed_image = knn_impute_image(X_missing_image, k=K_KNN)\n",
    "#     # X_imputed_flat = X_imputed_image.view(-1, N_FEATURES)\n",
    "#\n",
    "#     ari, nmi = run_dec_pipeline(\n",
    "#         tensor_x,\n",
    "#         labels,\n",
    "#         indices,\n",
    "#         device=device,\n",
    "#         ae_epochs=20,\n",
    "#         dec_epochs=75,\n",
    "#         n_clusters=10,\n",
    "#         latent_dim=10,\n",
    "#         n_features=784,\n",
    "#     )\n",
    "#\n",
    "#     ari_scores_knn.append(ari)\n",
    "#     nmi_scores_knn.append(nmi)\n",
    "\n",
    "# print(f\"\\n RESULTS ({mcar_percent}% MCAR): ARI={ari:.4f} | NMI={nmi:.4f}\")"
   ],
   "id": "ece114045c2fa086",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
